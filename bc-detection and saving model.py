# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J2T9R0kEvqJsU1mg3HLbxkbC72kSNPqr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import os

from google.colab import files
uploaded = files.upload()

data = pd.read_csv('wdbc.csv')

X = data.iloc[:, 2:].values
y = data.iloc[:, 1].values

# Encoding categorical data
from sklearn.preprocessing import LabelEncoder
labelencoder_X_1 = LabelEncoder()
y = labelencoder_X_1.fit_transform(y)

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)



import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Initialising the ANN
classifier = Sequential()

# Adding the input layer and the first hidden layer
classifier.add(Dense(16, kernel_initializer="uniform", activation='relu'))

# Adding dropout to prevent overfitting
#classifier.add(Dropout(p=0.1))

# Adding the second hidden layer
classifier.add(Dense(16, kernel_initializer='uniform', activation='relu'))
# Adding dropout to prevent overfitting
#classifier.add(Dropout(p=0.1))

# Adding the output layer
classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))

# Compiling the ANN
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, batch_size=100, epochs=150)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

from google.colab import drive
drive.mount('/content/drive')

print("Our accuracy is {}%".format(((cm[0][0] + cm[1][1])/57)*100))

sns.heatmap(cm,annot=True)
plt.savefig('h.png')



classifier.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(classifier)
tflite_model = converter.convert()

!mkdir -p saved_model
classifier.save('saved_model/my_model')

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

print("Our accuracy is {}%".format(((cm[0][0] + cm[1][1])/57)*100))

converter = tf.lite.TFLiteConverter.from_saved_model('saved_model/my_model', signature_keys=None,tags=None)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)

new_model = tf.keras.models.load_model('saved_model/my_model')

# Check its architecture
new_model.summary()
